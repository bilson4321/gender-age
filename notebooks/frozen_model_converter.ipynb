{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "width, height = 200, 200  # Adjust these dimensions based on your requirements\n",
    "channels = 1  # 1 for grayscale images, 3 for RGB images\n",
    "num_classes = 7  # Adjust based on the number of age classes in your dataset\n",
    "num_epochs = 6\n",
    "# batch_size = 502\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 12:45:33.566500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-15 12:45:33.566586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-15 12:45:33.566617: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-15 12:45:33.566837: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-15 12:45:33.566851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-15 12:45:33.566894: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-15 12:45:33.566933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5606 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the SavedModel\n",
    "loaded_model = tf.keras.models.load_model('./saved_model/')\n",
    "\n",
    "# Define a sample input (replace with your actual input shape)\n",
    "sample_input = tf.ones((1, width, height, channels))\n",
    "\n",
    "# Create a concrete function using tf.function\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=(None, width, height, channels), dtype=tf.float32)])\n",
    "def inference_fn(inputs):\n",
    "    return loaded_model(inputs)\n",
    "\n",
    "# Get the concrete function\n",
    "concrete_func = inference_fn.get_concrete_function(sample_input)\n",
    "\n",
    "# Convert the model to a frozen graph\n",
    "frozen_graph_def = tf.compat.v1.graph_util.convert_variables_to_constants(\n",
    "    tf.compat.v1.Session(graph=tf.Graph()), \n",
    "    concrete_func.graph.as_graph_def(), \n",
    "    [concrete_func.outputs[0].name.split(\":\")[0]]\n",
    ")\n",
    "\n",
    "# Save the frozen graph to a file\n",
    "with tf.io.gfile.GFile('frozen_model.pb', 'wb') as f:\n",
    "    f.write(frozen_graph_def.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'tf_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m tf_model_graph \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mtf_model(x))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# get concrete function\u001b[39;00m\n\u001b[1;32m     12\u001b[0m tf_model_graph \u001b[38;5;241m=\u001b[39m tf_model_graph\u001b[38;5;241m.\u001b[39mget_concrete_function(\n\u001b[0;32m---> 13\u001b[0m     tf\u001b[38;5;241m.\u001b[39mTensorSpec( \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_model\u001b[49m\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,  tf\u001b[38;5;241m.\u001b[39mtf_model\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# obtain frozen concrete function\u001b[39;00m\n\u001b[1;32m     15\u001b[0m frozen_tf_func \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mgraph_util\u001b[38;5;241m.\u001b[39mconvert_variables_to_constants_v2(tf_model_graph)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'tf_model'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "# define the directory for .pb model\n",
    "pb_model_path = \"models\"\n",
    "# define the name of .pb model\n",
    "pb_model_name = \"mobilenet.pb\"\n",
    "# create directory for further converted model\n",
    "os.makedirs(pb_model_path, exist_ok=True)\n",
    "# get model TF graph\n",
    "tf_model_graph = tf.function(lambda x: tf.tf_model(x))\n",
    "# get concrete function\n",
    "tf_model_graph = tf_model_graph.get_concrete_function(\n",
    "    tf.TensorSpec( tf.tf_model.inputs[0].shape,  tf.tf_model.inputs[0].dtype))\n",
    "# obtain frozen concrete function\n",
    "frozen_tf_func = tf.compat.v1.graph_util.convert_variables_to_constants_v2(tf_model_graph)\n",
    "# get frozen graph\n",
    "frozen_tf_func.graph.as_graph_def()\n",
    "# save full tf model\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_tf_func.graph,\n",
    "                  logdir=pb_model_path,\n",
    "                  name=pb_model_name,\n",
    "                  as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a concrete function with input signature\u001b[39;00m\n\u001b[1;32m      8\u001b[0m concrete_func \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;28;01mlambda\u001b[39;00m x: model(x))\n\u001b[0;32m----> 9\u001b[0m concrete_func \u001b[38;5;241m=\u001b[39m concrete_func\u001b[38;5;241m.\u001b[39mget_concrete_function(tf\u001b[38;5;241m.\u001b[39mTensorSpec(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m+\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m:], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the model to a TensorFlow graph and freeze it\u001b[39;00m\n\u001b[1;32m     12\u001b[0m frozen_func \u001b[38;5;241m=\u001b[39m convert_variables_to_constants_v2(concrete_func)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# Load your trained TensorFlow model\n",
    "loaded_model = tf.saved_model.load('./saved_model/')\n",
    "\n",
    "# Create a concrete function with input signature\n",
    "concrete_func = tf.function(lambda x: model(x))\n",
    "concrete_func = concrete_func.get_concrete_function(tf.TensorSpec(shape=(None,) + model.input_shape[1:], dtype=tf.float32))\n",
    "\n",
    "# Convert the model to a TensorFlow graph and freeze it\n",
    "frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir='./frozen_model',\n",
    "                  name='frozen_model.pb',\n",
    "                  as_text=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
