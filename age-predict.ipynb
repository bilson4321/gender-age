{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 20:41:24.279117: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 20:41:24.279182: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 20:41:24.325039: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 20:41:24.421165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 20:41:25.398635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from zipfile import ZipFile\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "width, height = 200, 200  # Adjust these dimensions based on your requirements\n",
    "channels = 3  # Assuming RGB images\n",
    "num_classes = 105  # Adjust based on the number of age classes in your dataset\n",
    "num_epochs = 20\n",
    "batch_size = 502\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done unzipping combined_faces.zip\n"
     ]
    }
   ],
   "source": [
    "combined_faces_zip_path = \"./assets/combined_faces.zip\"\n",
    "with ZipFile(combined_faces_zip_path, 'r') as myzip:\n",
    "    myzip.extractall()\n",
    "    print('Done unzipping combined_faces.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              filename  age\n",
      "0   ./content/combined_faces/8_163.jpg    8\n",
      "1   ./content/combined_faces/38_66.jpg   38\n",
      "2  ./content/combined_faces/40_177.jpg   40\n",
      "3  ./content/combined_faces/36_267.jpg   36\n",
      "4   ./content/combined_faces/8_349.jpg    8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('./assets/images_filenames_labels_test.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand the structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image file paths and corresponding labels\n",
    "file_paths = df['filename'].tolist()  # replace 'image_path_column' with the actual column name\n",
    "labels = df['age'].tolist()  # replace 'age_column' with the actual column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Reshape the labels to a 2D array\n",
    "labels_reshaped = np.array(labels).reshape(-1, 1)\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the labels to one-hot encoded vectors\n",
    "one_hot_labels = encoder.fit_transform(labels_reshaped).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path, target_size=(height, width)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img\n",
    "\n",
    "preprocessed_images = [preprocess_image(path) for path in file_paths]\n",
    "combined_data = list(zip(preprocessed_images, one_hot_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, label in combined_data[:5]:  # Display information for the first 5 samples\n",
    "#     print(f\"Image shape: {img.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6428\n",
      "Number of validation samples: 1608\n",
      "Number of test samples: 2010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume combined_data is a list of tuples containing images and labels\n",
    "# (preprocessed_images, one_hot_labels)\n",
    "# Replace this with your actual combined_data variable\n",
    "\n",
    "# Extract images and labels\n",
    "images, labels = zip(*combined_data)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print the sizes of the resulting datasets\n",
    "print(f\"Number of training samples: {len(train_images)}\")\n",
    "print(f\"Number of validation samples: {len(val_images)}\")\n",
    "print(f\"Number of test samples: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 20:41:47.168855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.353757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.353841: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.355924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.355979: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.356013: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.625245: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.625309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.625317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-14 20:41:47.625384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-14 20:41:47.625405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5606 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, channels)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6428\n",
      "Number of training labels: 6428\n",
      "Number of val samples: 1608\n",
      "Number of val labels: 1608\n",
      "(200, 200, 3)\n",
      "(200, 200, 3)\n",
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(train_images)}\")\n",
    "print(f\"Number of training labels: {len(train_labels)}\")\n",
    "print(f\"Number of val samples: {len(val_images)}\")\n",
    "print(f\"Number of val labels: {len(val_labels)}\")\n",
    "\n",
    "\n",
    "print(train_images[0].shape)\n",
    "print(val_images[0].shape)\n",
    "print(test_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=num_epochs, batch_size=batch_size, validation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test Accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./image.jpg')\n",
    "img = cv2.resize(img, (width, height))\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img)\n",
    "predicted_age = np.argmax(prediction)\n",
    "print(f'Predicted Age: {predicted_age}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img)\n",
    "predicted_age = np.argmax(prediction)\n",
    "print(f'Predicted Age: {predicted_age}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
