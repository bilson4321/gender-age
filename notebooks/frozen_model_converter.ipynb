{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the SavedModel\n",
    "loaded_model = tf.saved_model.load('./saved_model/')\n",
    "\n",
    "# Define a sample input (replace with your actual input shape)\n",
    "sample_input = tf.ones((1, 200, 200, 1), dtype=tf.float32)\n",
    "\n",
    "# Create a concrete function using tf.function\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=(None, 200, 200, 1), dtype=tf.float32)])\n",
    "def inference_fn(inputs):\n",
    "    return loaded_model(inputs)\n",
    "\n",
    "# Get the concrete function\n",
    "concrete_func = inference_fn.get_concrete_function(sample_input)\n",
    "\n",
    "# Convert the model to a frozen graph\n",
    "frozen_graph_def = tf.compat.v1.graph_util.convert_variables_to_constants(\n",
    "    tf.compat.v1.Session(graph=tf.Graph()), \n",
    "    concrete_func.graph.as_graph_def(), \n",
    "    [concrete_func.outputs[0].name.split(\":\")[0]]\n",
    ")\n",
    "\n",
    "# Save the frozen graph to a file\n",
    "with tf.io.gfile.GFile('frozen_model.pb', 'wb') as f:\n",
    "    f.write(frozen_graph_def.SerializeToString())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
